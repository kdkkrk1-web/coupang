
import os
import requests
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta, timezone
from urllib.parse import urlencode
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound

# ----------------------
# Helpers
# ----------------------

def iso8601_duration_to_seconds(duration):
    # e.g., PT1H2M10S
    hours = minutes = seconds = 0
    num = ''
    in_time = False
    for ch in duration:
        if ch.isdigit():
            num += ch
        elif ch == 'P':
            continue
        elif ch == 'T':
            in_time = True
        elif ch == 'H' and in_time:
            hours = int(num) if num else 0
            num = ''
        elif ch == 'M' and in_time:
            minutes = int(num) if num else 0
            num = ''
        elif ch == 'S' and in_time:
            seconds = int(num) if num else 0
            num = ''
    return hours*3600 + minutes*60 + seconds

def seconds_to_mmss(total_seconds: int):
    m, s = divmod(int(total_seconds), 60)
    h, m = divmod(m, 60)
    if h:
        return f"{h:02d}:{m:02d}:{s:02d}"
    return f"{m:02d}:{s:02d}"

def human_int(n):
    try:
        n = int(n)
    except Exception:
        return n
    for unit in ['','ì²œ','ë§Œ','ì–µ']:
        if abs(n) < 10000 or unit == 'ì–µ':
            return f"{n}{unit}"
        n = n//10000

def get_env_api_key():
    key = os.getenv("YOUTUBE_API_KEY", "").strip()
    return key

# ----------------------
# Streamlit UI
# ----------------------
st.set_page_config(page_title="YouTube íƒìƒ‰ & ëŒ€ëŸ‰ ë¹„êµ + ìë§‰ ìˆ˜ì§‘", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š YouTube íƒìƒ‰ & ëŒ€ëŸ‰ ë¹„êµ (2~100ê°œ) + ğŸ’¬ ìë§‰ ìˆ˜ì§‘")

with st.sidebar:
    st.markdown("### ğŸ”‘ API í‚¤ ì„¤ì •")
    st.markdown("Google Cloud ì½˜ì†”ì—ì„œ **YouTube Data API v3** API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
    api_key_input = st.text_input("YOUTUBE_API_KEY", value=os.getenv("YOUTUBE_API_KEY",""), type="password")
    if api_key_input:
        os.environ["YOUTUBE_API_KEY"] = api_key_input

tab_search, tab_selected = st.tabs(["ğŸ” íƒìƒ‰/í•„í„° ê²€ìƒ‰", "âœ… ì„ íƒ ì˜ìƒ ë¹„êµ & ìë§‰ ìˆ˜ì§‘"])

with tab_search:
    col1, col2, col3 = st.columns(3)
    with col1:
        keyword = st.text_input("í‚¤ì›Œë“œ(ë¹„ì›Œë‘ë©´ ì¸ê¸°ì˜ìƒ)", value="ì¿ íŒ¡ê¿€í…œ")
        max_results = st.number_input("ìµœëŒ€ ê²°ê³¼ ìˆ˜", min_value=2, max_value=100, value=10, step=1)
    with col2:
        upload_period = st.selectbox("ì—…ë¡œë“œ ì‹œê¸°", options=["ì „ì²´ê¸°ê°„", "ì´ë²ˆë‹¬", "ì´ë²ˆì£¼", "ì˜¤ëŠ˜"], index=1)
        duration_filter = st.selectbox("ì˜ìƒ ê¸¸ì´", options=["ì „ì²´", "4ë¶„ ë¯¸ë§Œ", "4~20ë¶„", "20ë¶„ ì´ìƒ"], index=1)
    with col3:
        order = st.selectbox("ì •ë ¬", options=[("viewCount(ì¡°íšŒìˆœ)","viewCount"),("date(ìµœì‹ ìˆœ)","date"),("relevance(ê´€ë ¨ìˆœ)","relevance")], format_func=lambda x:x[0])
        select_cap = st.number_input("í•œ ë²ˆì— ì„ íƒí•  ê°œìˆ˜", min_value=2, max_value=50, value=5, step=1)

    if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
        api_key = get_env_api_key()
        if not api_key:
            st.error("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— YOUTUBE_API_KEYë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()

        # publishedAfter
        now = datetime.now(timezone.utc)
        if upload_period == "ì´ë²ˆë‹¬":
            start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        elif upload_period == "ì´ë²ˆì£¼":
            start = now - timedelta(days=now.weekday())  # Monday
            start = start.replace(hour=0, minute=0, second=0, microsecond=0)
        elif upload_period == "ì˜¤ëŠ˜":
            start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        else:
            start = None

        params = {
            "part": "snippet",
            "type": "video",
            "maxResults": min(max_results, 50),  # YouTube API limit per page
            "order": order[1],
            "q": keyword if keyword else None,
            "key": api_key
        }
        if start:
            params["publishedAfter"] = start.isoformat()
        # duration with videoDefinition or videoDuration only works in search if using 'videoDuration' param
        # But search supports videoDuration filter: any, short(<4m), medium(4-20m), long(>20m)
        duration_map = {"ì „ì²´":"any", "4ë¶„ ë¯¸ë§Œ":"short", "4~20ë¶„":"medium", "20ë¶„ ì´ìƒ":"long"}
        params["videoDuration"] = duration_map[duration_filter]

        search_url = "https://www.googleapis.com/youtube/v3/search"
        items = []
        next_page = None
        needed = int(max_results)
        while needed > 0:
            page_params = params.copy()
            if next_page:
                page_params["pageToken"] = next_page
            r = requests.get(search_url, params=page_params, timeout=20)
            r.raise_for_status()
            data = r.json()
            items.extend(data.get("items", []))
            next_page = data.get("nextPageToken")
            if not next_page or len(items) >= max_results:
                break
            needed = max_results - len(items)

        video_ids = [it["id"]["videoId"] for it in items if it.get("id",{}).get("videoId")]
        if not video_ids:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # Get details
        vid_chunks = [video_ids[i:i+50] for i in range(0, len(video_ids), 50)]
        details = []
        for chunk in vid_chunks:
            params_v = {
                "part": "snippet,contentDetails,statistics",
                "id": ",".join(chunk),
                "key": api_key
            }
            r = requests.get("https://www.googleapis.com/youtube/v3/videos", params=params_v, timeout=20)
            r.raise_for_status()
            details.extend(r.json().get("items", []))

        rows = []
        for it in details:
            vid = it["id"]
            sn = it.get("snippet", {})
            cd = it.get("contentDetails", {})
            stt = it.get("statistics", {})
            dur_sec = iso8601_duration_to_seconds(cd.get("duration", "PT0S"))
            rows.append({
                "ì„ íƒ": False,
                "videoId": vid,
                "ì¸ë„¤ì¼": sn.get("thumbnails",{}).get("default",{}).get("url",""),
                "ì œëª©": sn.get("title",""),
                "ì±„ë„ëª…": sn.get("channelTitle",""),
                "ê²Œì‹œì¼": sn.get("publishedAt","")[:10],
                "ì¡°íšŒìˆ˜": int(stt.get("viewCount","0")) if "viewCount" in stt else 0,
                "ëŒ“ê¸€ìˆ˜": int(stt.get("commentCount","0")) if "commentCount" in stt else 0,
                "ì˜ìƒ ê¸¸ì´(ë¶„:ì´ˆ)": seconds_to_mmss(dur_sec),
                "URL": f"https://www.youtube.com/watch?v={vid}",
            })

        df = pd.DataFrame(rows).sort_values(by="ì¡°íšŒìˆ˜", ascending=False if order[1]=="viewCount" else True)
        st.session_state["search_df"] = df
        st.session_state["select_cap"] = int(select_cap)
        st.success(f"ê°€ì ¸ì˜¨ ì˜ìƒ {len(df)}ê°œ")
        st.dataframe(df.drop(columns=["videoId"]), use_container_width=True, hide_index=True)

with tab_selected:
    df = st.session_state.get("search_df")
    cap = st.session_state.get("select_cap", 5)
    if df is None:
        st.info("ë¨¼ì € 'íƒìƒ‰/í•„í„° ê²€ìƒ‰' íƒ­ì—ì„œ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        st.markdown(f"**í•œ ë²ˆì— ì„ íƒí•  ê°œìˆ˜ ì œí•œ:** {cap}ê°œ")
        editable_df = st.data_editor(
            df,
            column_config={
                "ì¸ë„¤ì¼": st.column_config.ImageColumn("ì¸ë„¤ì¼", help="ì˜ìƒ ì¸ë„¤ì¼"),
                "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", help="ìë§‰ ìˆ˜ì§‘ ëŒ€ìƒ ì„ íƒ"),
                "URL": st.column_config.LinkColumn("URL"),
            },
            hide_index=True,
            use_container_width=True,
            num_rows="dynamic",
        )

        selected = editable_df[editable_df["ì„ íƒ"] == True]
        if len(selected) > cap:
            st.error(f"ì„ íƒ ê°œìˆ˜ {len(selected)}ê°œ â€” ì œí•œ {cap}ê°œ ì´í•˜ë¡œ ì¤„ì—¬ì£¼ì„¸ìš”.")
            st.stop()

        if st.button("ğŸ’¬ ì„ íƒ ì˜ìƒ ìë§‰ ìˆ˜ì§‘"):
            transcripts = []
            for _, row in selected.iterrows():
                vid = row["videoId"]
                title = row["ì œëª©"]
                url = row["URL"]
                # Try KO first then auto
                langs_try = ["ko", "a.en", "en"]
                transcript_text = ""
                found_lang = None
                try:
                    available = YouTubeTranscriptApi.list_transcripts(vid)
                    # prefer Korean, else first translatable
                    for pref in ["ko", "ja", "en"]:
                        if available.find_manually_created_transcript([pref]):
                            t = available.find_manually_created_transcript([pref]).fetch()
                            transcript_text = " ".join([x["text"] for x in t])
                            found_lang = pref
                            break
                    if not transcript_text:
                        # fallback: any
                        t = available.find_generated_transcript(available._TranscriptList__languages).fetch()
                        transcript_text = " ".join([x["text"] for x in t])
                        found_lang = t[0].get("language", "auto")
                except (TranscriptsDisabled, NoTranscriptFound):
                    transcript_text = "(ìë§‰ ì—†ìŒ)"
                except Exception as e:
                    transcript_text = f"(ì—ëŸ¬: {e})"

                transcripts.append({
                    "ì œëª©": title,
                    "URL": url,
                    "ìë§‰": transcript_text
                })

            tdf = pd.DataFrame(transcripts)
            st.session_state["transcripts_df"] = tdf
            st.success(f"ìë§‰ ìˆ˜ì§‘ ì™„ë£Œ: {len(tdf)}ê°œ")
            st.dataframe(tdf[["ì œëª©","URL"]], use_container_width=True, hide_index=True)

        tdf = st.session_state.get("transcripts_df")
        if tdf is not None and not tdf.empty:
            colA, colB = st.columns(2)
            with colA:
                csv = tdf.to_csv(index=False).encode("utf-8-sig")
                st.download_button("â¬‡ï¸ ìë§‰ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="youtube_transcripts.csv", mime="text/csv")
            with colB:
                # plain text export
                lines = []
                for _, r in tdf.iterrows():
                    lines.append(f"# {r['ì œëª©']}\n{r['URL']}\n{r['ìë§‰']}\n")
                txt = "\n\n".join(lines).encode("utf-8")
                st.download_button("â¬‡ï¸ ìë§‰ TXT ë‹¤ìš´ë¡œë“œ", data=txt, file_name="youtube_transcripts.txt", mime="text/plain")
